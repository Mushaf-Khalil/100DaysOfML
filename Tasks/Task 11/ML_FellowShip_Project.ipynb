{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "cell_execution_strategy": "setup"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "source": [
        "## Data loading\n",
        "\n",
        "### Subtask:\n",
        "Load the two CSV files into pandas DataFrames.\n"
      ],
      "cell_type": "markdown",
      "metadata": {
        "id": "WQBRbdN9f2mI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import files\n",
        "\n",
        "# uploaded = files.upload()\n"
      ],
      "metadata": {
        "id": "CeNPpeTf2CtD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "**Reasoning**:\n",
        "Load the two CSV files into pandas DataFrames.\n",
        "\n"
      ],
      "cell_type": "markdown",
      "metadata": {
        "id": "Z8VVoGdyf228"
      }
    },
    {
      "source": [
        "import pandas as pd\n",
        "\n",
        "movies = pd.read_csv(\"tmdb_5000_movies.csv\")\n",
        "credits = pd.read_csv(\"tmdb_5000_credits.csv\")"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "_ninQwmFf3G8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "## Data preparation\n",
        "\n",
        "### Subtask:\n",
        "Merge the two dataframes, `movies` and `credits`, based on the 'title' column.\n"
      ],
      "cell_type": "markdown",
      "metadata": {
        "id": "CrOJ2IvDgAjo"
      }
    },
    {
      "source": [
        "**Reasoning**:\n",
        "Merge the movies and credits dataframes on the 'title' column.\n",
        "\n"
      ],
      "cell_type": "markdown",
      "metadata": {
        "id": "vcSGVP2cgAz0"
      }
    },
    {
      "source": [
        "movies = movies.merge(credits, on='title')"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "Abqyyt4OgBDo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "## Data wrangling\n",
        "\n",
        "### Subtask:\n",
        "Select relevant columns and extract information from specific columns using the provided helper function.\n"
      ],
      "cell_type": "markdown",
      "metadata": {
        "id": "AFsQMKfxgE_t"
      }
    },
    {
      "source": [
        "**Reasoning**:\n",
        "Select the relevant columns and apply the extract_names function to the specified columns, modifying it for the 'crew' column to extract directors' names.\n",
        "\n"
      ],
      "cell_type": "markdown",
      "metadata": {
        "id": "wwnfpX0FgF1z"
      }
    },
    {
      "source": [
        "# Keep only required columns\n",
        "movies = movies[['movie_id', 'title', 'overview', 'genres', 'keywords', 'cast', 'crew']]\n",
        "\n",
        "# Function to convert stringified list to list of names\n",
        "def extract_names(obj, key='name', limit=None):\n",
        "    try:\n",
        "        items = ast.literal_eval(obj)\n",
        "        if key == 'name':\n",
        "            names = [item[key] for item in items]\n",
        "            if limit:\n",
        "                names = names[:limit]\n",
        "            return names\n",
        "        elif key == 'job' and isinstance(items, list):\n",
        "            names = [item['name'] for item in items if item.get('job') == 'Director']\n",
        "            return names\n",
        "        return []\n",
        "    except:\n",
        "        return []\n",
        "\n",
        "# Extract genres, keywords, cast (top 3), director\n",
        "movies['genres'] = movies['genres'].apply(lambda x: extract_names(x))\n",
        "movies['keywords'] = movies['keywords'].apply(lambda x: extract_names(x))\n",
        "movies['cast'] = movies['cast'].apply(lambda x: extract_names(x, limit=3))\n",
        "movies['crew'] = movies['crew'].apply(lambda x: extract_names(x, key='job'))"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "Qtrph-rlgGGA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "import ast\n",
        "\n",
        "# Keep only required columns\n",
        "movies = movies[['movie_id', 'title', 'overview', 'genres', 'keywords', 'cast', 'crew']]\n",
        "\n",
        "# Function to convert stringified list to list of names\n",
        "def extract_names(obj, key='name', limit=None):\n",
        "    try:\n",
        "        items = ast.literal_eval(obj)\n",
        "        if key == 'name':\n",
        "            names = [item[key] for item in items]\n",
        "            if limit:\n",
        "                names = names[:limit]\n",
        "            return names\n",
        "        elif key == 'job' and isinstance(items, list):\n",
        "            names = [item['name'] for item in items if item.get('job') == 'Director']\n",
        "            return names\n",
        "        return []\n",
        "    except (ValueError, TypeError, IndexError):\n",
        "        return []\n",
        "\n",
        "# Extract genres, keywords, cast (top 3), director\n",
        "movies.loc[:, 'genres'] = movies['genres'].apply(lambda x: extract_names(x))\n",
        "movies.loc[:, 'keywords'] = movies['keywords'].apply(lambda x: extract_names(x))\n",
        "movies.loc[:, 'cast'] = movies['cast'].apply(lambda x: extract_names(x, limit=3))\n",
        "movies.loc[:, 'crew'] = movies['crew'].apply(lambda x: extract_names(x, key='job'))"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "2ENrnPNngIDH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "**Reasoning**:\n",
        "The error message indicates that the `ast` module is not imported.  I need to import it before using `ast.literal_eval`.\n",
        "\n"
      ],
      "cell_type": "markdown",
      "metadata": {
        "id": "22c18xBfgKNZ"
      }
    },
    {
      "source": [
        "import ast\n",
        "\n",
        "# Load the original movie dataset to retrieve the required columns\n",
        "movies = pd.read_csv(\"tmdb_5000_movies.csv\")\n",
        "credits = pd.read_csv(\"tmdb_5000_credits.csv\")\n",
        "movies = movies.merge(credits, on='title')\n",
        "\n",
        "\n",
        "# Now you can select the required columns\n",
        "movies = movies[['movie_id', 'title', 'overview', 'genres', 'keywords', 'cast', 'crew']]\n",
        "\n",
        "# ... (rest of your code) ...\n",
        "# Function to convert stringified list to list of names\n",
        "def extract_names(obj, key='name', limit=None):\n",
        "    try:\n",
        "        items = ast.literal_eval(obj)\n",
        "        if key == 'name':\n",
        "            names = [item[key] for item in items]\n",
        "            if limit:\n",
        "                names = names[:limit]\n",
        "            return names\n",
        "        elif key == 'job' and isinstance(items, list):\n",
        "            names = [item['name'] for item in items if item.get('job') == 'Director']\n",
        "            return names\n",
        "        return []\n",
        "    except (ValueError, TypeError, IndexError):\n",
        "        return []\n",
        "\n",
        "# Extract genres, keywords, cast (top 3), director\n",
        "movies.loc[:, 'genres'] = movies['genres'].apply(lambda x: extract_names(x))\n",
        "movies.loc[:, 'keywords'] = movies['keywords'].apply(lambda x: extract_names(x))\n",
        "movies.loc[:, 'cast'] = movies['cast'].apply(lambda x: extract_names(x, limit=3))\n",
        "movies.loc[:, 'crew'] = movies['crew'].apply(lambda x: extract_names(x, key='job'))"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "j0oTiBEagKdP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "## Feature engineering\n",
        "\n",
        "### Subtask:\n",
        "Combine the relevant text columns ('overview', 'genres', 'keywords', 'cast', 'crew') into a new 'tags' column.\n"
      ],
      "cell_type": "markdown",
      "metadata": {
        "id": "dudXcV_ygNwe"
      }
    },
    {
      "source": [
        "**Reasoning**:\n",
        "Combine the relevant text columns ('overview', 'genres', 'keywords', 'cast', 'crew') into a new 'tags' column, handling missing values in 'overview'.\n",
        "\n"
      ],
      "cell_type": "markdown",
      "metadata": {
        "id": "sLFulfoVgOAg"
      }
    },
    {
      "source": [
        "# Fill missing values in 'overview' with empty strings\n",
        "movies['overview'] = movies['overview'].fillna('')\n",
        "\n",
        "# Combine text fields into a single 'tags' column\n",
        "movies['tags'] = movies['overview'] + ' ' + \\\n",
        "                 movies['genres'].apply(lambda x: ' '.join(x)) + ' ' + \\\n",
        "                 movies['keywords'].apply(lambda x: ' '.join(x)) + ' ' + \\\n",
        "                 movies['cast'].apply(lambda x: ' '.join(x)) + ' ' + \\\n",
        "                 movies['crew'].apply(lambda x: ' '.join(x))"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "OVqkOrLigOQZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "## Data preparation\n",
        "\n",
        "### Subtask:\n",
        "Drop unnecessary columns from the DataFrame, leaving only 'movie_id', 'title', and 'tags'.\n"
      ],
      "cell_type": "markdown",
      "metadata": {
        "id": "7Uu83PTAgRbZ"
      }
    },
    {
      "source": [
        "**Reasoning**:\n",
        "Select only the required columns 'movie_id', 'title', and 'tags' from the movies DataFrame.\n",
        "\n"
      ],
      "cell_type": "markdown",
      "metadata": {
        "id": "GnNLBeG7gRrY"
      }
    },
    {
      "source": [
        "movies = movies[['movie_id', 'title', 'tags']]"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "KYz8SSuCgR7a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "## Summary:\n",
        "\n",
        "### 1. Q&A\n",
        "\n",
        "No questions were posed in the provided task description.\n",
        "\n",
        "\n",
        "### 2. Data Analysis Key Findings\n",
        "\n",
        "*   The datasets `tmdb_5000_movies.csv` and `tmdb_5000_credits.csv` were successfully merged based on the 'title' column.\n",
        "*   A new 'tags' column was created by combining 'overview', 'genres', 'keywords', 'cast', and 'crew' information, creating a text-based representation of each movie for content-based filtering.\n",
        "*   The 'cast' column was limited to the top 3 actors for each movie.\n",
        "*   Only the director's name was extracted from the 'crew' column.\n",
        "*   Missing values in the 'overview' column were filled with empty strings.\n",
        "\n",
        "\n",
        "### 3. Insights or Next Steps\n",
        "\n",
        "*   The 'tags' column is now ready for text vectorization techniques (TF-IDF, word embeddings) to build a content-based movie recommendation system.\n",
        "*   Explore other features like budget, revenue, popularity, and vote counts to incorporate into the recommendation model for a more comprehensive approach.\n"
      ],
      "cell_type": "markdown",
      "metadata": {
        "id": "fZBJmyIMgXEj"
      }
    },
    {
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import ast\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "import pickle\n",
        "\n",
        "def build_movie_recommendation_model():\n",
        "    \"\"\"Builds and saves the movie recommendation model.\"\"\"\n",
        "\n",
        "    # Download NLTK resources if not already downloaded\n",
        "    nltk.download('stopwords')\n",
        "\n",
        "    # Load datasets\n",
        "    movies = pd.read_csv(\"tmdb_5000_movies.csv\")\n",
        "    credits = pd.read_csv(\"tmdb_5000_credits.csv\")\n",
        "    movies = movies.merge(credits, on='title')\n",
        "\n",
        "    # Keep only required columns\n",
        "    movies = movies[['movie_id', 'title', 'overview', 'genres', 'keywords', 'cast', 'crew']].copy() # Use .copy() to avoid SettingWithCopyWarning\n",
        "\n",
        "    # Drop rows with missing titles\n",
        "    movies.dropna(subset=['title'], inplace=True)\n",
        "\n",
        "    # Function to convert stringified list to list of names\n",
        "    def extract_names(obj, key='name', limit=None):\n",
        "        try:\n",
        "            items = ast.literal_eval(obj)\n",
        "            if key == 'name':\n",
        "                names = [item[key] for item in items]\n",
        "                if limit:\n",
        "                    names = names[:limit]\n",
        "                return names\n",
        "            elif key == 'job' and isinstance(items, list):\n",
        "                names = [item['name'] for item in items if item.get('job') == 'Director']\n",
        "                return names\n",
        "            return []\n",
        "        except (ValueError, TypeError, IndexError):\n",
        "            return []\n",
        "\n",
        "    # Extract genres, keywords, cast (top 3), director\n",
        "    movies.loc[:, 'genres'] = movies['genres'].apply(lambda x: extract_names(x))\n",
        "    movies.loc[:, 'keywords'] = movies['keywords'].apply(lambda x: extract_names(x))\n",
        "    movies.loc[:, 'cast'] = movies['cast'].apply(lambda x: extract_names(x, limit=3))\n",
        "    movies.loc[:, 'crew'] = movies['crew'].apply(lambda x: extract_names(x, key='job'))\n",
        "\n",
        "    # Fill missing values in 'overview' with empty strings\n",
        "    movies['overview'] = movies['overview'].fillna('')\n",
        "\n",
        "    # Combine text fields into a single 'tags' column\n",
        "    movies['tags'] = movies['overview'] + ' ' + \\\n",
        "                    movies['genres'].apply(lambda x: ' '.join(x)) + ' ' + \\\n",
        "                    movies['keywords'].apply(lambda x: ' '.join(x)) + ' ' + \\\n",
        "                    movies['cast'].apply(lambda x: ' '.join(x)) + ' ' + \\\n",
        "                    movies['crew'].apply(lambda x: ' '.join(x))\n",
        "\n",
        "    # Data Cleaning and Preprocessing\n",
        "    ps = PorterStemmer()\n",
        "\n",
        "    def clean_tags(text):\n",
        "        text = re.sub('[^a-zA-Z0-9 ]', '', text)\n",
        "        text = text.lower()\n",
        "        text = ' '.join([ps.stem(word) for word in text.split() if word not in stopwords.words('english')])\n",
        "        return text\n",
        "\n",
        "    movies['tags'] = movies['tags'].apply(clean_tags)\n",
        "\n",
        "    # Text Vectorization and Similarity Calculation\n",
        "    tfidf = TfidfVectorizer(stop_words='english')\n",
        "    tfidf_matrix = tfidf.fit_transform(movies['tags'])\n",
        "    cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
        "\n",
        "    # Create the indices mapping\n",
        "    indices = pd.Series(movies.index, index=movies['title'].apply(lambda x: re.sub(r'[- ]', '', x).lower())).drop_duplicates()\n",
        "\n",
        "    # --- Modified Saving for compatibility with api.py ---\n",
        "    model_data = {\n",
        "        'cosine_sim': cosine_sim,\n",
        "        'movies': movies[['title', 'overview']].to_dict(orient='records'), # Save relevant movie info\n",
        "        'indices': indices.to_dict()\n",
        "    }\n",
        "\n",
        "    with open('movie_recommendation_model.pkl', 'wb') as f:\n",
        "        pickle.dump(model_data, f)\n",
        "\n",
        "    print(\"Model data saved successfully to 'movie_recommendation_model.pkl' in the format expected by the API.\")\n",
        "\n",
        "def get_recommendations(title, model_path='movie_recommendation_model.pkl'):\n",
        "    \"\"\"Loads the model and generates movie recommendations, handling missing titles and ignoring characters.\"\"\"\n",
        "\n",
        "    with open(model_path, 'rb') as f:\n",
        "        model_data = pickle.load(f)\n",
        "\n",
        "    cosine_sim = model_data['cosine_sim']\n",
        "    movies_list = model_data['movies']\n",
        "    indices_dict = model_data['indices']\n",
        "    movies_df = pd.DataFrame(movies_list)\n",
        "    indices = pd.Series(indices_dict)\n",
        "\n",
        "    processed_title = re.sub(r'[- ]', '', title).lower()\n",
        "\n",
        "    if processed_title not in indices:\n",
        "        print(f\"Movie title '{title}' not found. Please try a different spelling.\")\n",
        "        return None\n",
        "\n",
        "    idx = indices[processed_title]\n",
        "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
        "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
        "    sim_scores = sim_scores[1:11]  # Get top 10 similar movies\n",
        "    movie_indices = [i[0] for i in sim_scores]\n",
        "    return movies_df['title'].iloc[movie_indices].tolist()\n",
        "\n",
        "# Build the model when the script is run\n",
        "if __name__ == \"__main__\":\n",
        "    build_movie_recommendation_model()\n",
        "\n",
        "    # --- Testing with loop for invalid titles ---\n",
        "    while True:\n",
        "        title = input(\"Enter a movie title: \")\n",
        "        recommendations = get_recommendations(title)\n",
        "\n",
        "        if recommendations is not None:  # Recommendations were generated\n",
        "            print(\"Recommendations:\")\n",
        "            for rec in recommendations:\n",
        "                print(f\"- {rec}\")\n",
        "            break  # Exit the loop"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "ytzBGgXfkVLl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79a6462a-e1d2-4aed-edce-2be5ff62a45c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model data saved successfully to 'movie_recommendation_model.pkl' in the format expected by the API.\n",
            "Enter a movie title: tangled\n",
            "Recommendations:\n",
            "- Into the Woods\n",
            "- Enchanted\n",
            "- The NeverEnding Story\n",
            "- The Green Mile\n",
            "- Ella Enchanted\n",
            "- Happily N'Ever After\n",
            "- A Simple Wish\n",
            "- The Princess and the Frog\n",
            "- The Horse Whisperer\n",
            "- Pocahontas\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming you have your 'get_recommendations' function defined\n",
        "recommendations = get_recommendations('Tangled')\n",
        "print(recommendations)  # Check if the recommendations are similar in genre, theme, etc."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pnG0ERVNceWj",
        "outputId": "0d1e7280-1a23-47da-b664-c8dd27551410"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Into the Woods', 'Enchanted', 'The NeverEnding Story', 'The Green Mile', 'Ella Enchanted', \"Happily N'Ever After\", 'A Simple Wish', 'The Princess and the Frog', 'The Horse Whisperer', 'Pocahontas']\n"
          ]
        }
      ]
    }
  ]
}